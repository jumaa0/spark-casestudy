{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed39b9b-386b-4787-b429-f8700d3afe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_sales count: 1500\n",
      "dim_product count: 30\n",
      "dim_agent count: 10\n",
      "dim_sales count: 1500\n",
      "daily_dump_df count: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum as spark_sum, col\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def create_spark_session(app_name=\"daily_dump\"):\n",
    "    return SparkSession.builder \\\n",
    "        .appName(app_name) \\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://localhost:9083\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "spark = create_spark_session()\n",
    "\n",
    "# Load data from Hive tables\n",
    "fact_sales = spark.table(\"casestudy.fact_sales\")\n",
    "dim_product = spark.table(\"casestudy.dim_product\")\n",
    "dim_agent = spark.table(\"casestudy.dim_agent\")\n",
    "dim_sales = spark.table(\"casestudy.dim_sales\")  # Assuming this is where transaction_date resides\n",
    "\n",
    "# Verify data is loaded\n",
    "print(\"fact_sales count:\", fact_sales.count())\n",
    "print(\"dim_product count:\", dim_product.count())\n",
    "print(\"dim_agent count:\", dim_agent.count())\n",
    "print(\"dim_sales count:\", dim_sales.count())\n",
    "\n",
    "# Join tables to get the necessary data\n",
    "daily_dump_df = fact_sales.join(dim_agent, fact_sales[\"sales_agent_id\"] == dim_agent[\"sales_person_id\"], \"inner\") \\\n",
    "                          .join(dim_product, fact_sales[\"product_id\"] == dim_product[\"product_id\"], \"inner\") \\\n",
    "                          .join(dim_sales, fact_sales[\"transaction_id\"] == dim_sales[\"transaction_id\"], \"inner\") \\\n",
    "                          .select(dim_agent[\"sales_agent_name\"], dim_product[\"product_name\"], fact_sales[\"total_paid_price_after_discount\"], dim_sales[\"transaction_date\"])\n",
    "\n",
    "# Verify join results\n",
    "print(\"daily_dump_df count:\", daily_dump_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfee965-8a5a-44c0-8b43-d59fa9188d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
